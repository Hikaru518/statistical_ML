{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-means clustering\n",
    "In this  problem, you will implement the k-means algorithm and use it\n",
    "for image compression. You will first start on an example 2D dataset that\n",
    "will help you gain intuition about how the k-means algorithm works. After\n",
    "that, you will use the k-means algorithm for image compression by reducing\n",
    "the number of colors that occur in an image to only those that are most\n",
    "common in that image. The relevant files for this part are in the folder **kmeans**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "import utils_kmeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The k-means algorithm\n",
    "The k-means algorithm is a method to automatically cluster similar \n",
    "examples together. That is, given a training set $\\{x^{(1)},\\ldots, x^{(m)}\\}$\n",
    "(where $x^{(i)} \\in \\Re^d$), k-means groups the data into a few cohesive clusters.\n",
    "The intuition behind k-means is an iterative procedure that starts by guessing\n",
    "the initial cluster centroids, and then refines this guess by repeatedly assigning\n",
    "examples to their closest centroids and then recomputing the centroids based\n",
    "on the assignments.\n",
    "The k-means algorithm is as follows:\n",
    "\n",
    "```python\n",
    "# Initialize centroids\n",
    "centroids = kmeans_init_centroids(X, K)\n",
    "for iter in range(iterations):\n",
    "   # Cluster assignment step: Assign each data point to the closest centroid. \n",
    "   idx = find_closest_centroids(X, centroids)\n",
    "   # Move centroid step: Compute means based on centroid assignments\n",
    "   centroids = compute_centroids(X, idx, K)\n",
    "```\n",
    "The inner-loop of the algorithm repeatedly carries out two steps: (i) Assigning each training example $x^{(i)}$ to its closest centroid, and (ii) Recomputing each centroid using the points assigned to it. The k-means algorithm will always converge to some final set of centroids. Note that the converged solution may not always be ideal and will depend on the initial setting of the centroids. Therefore, in practice the k-means algorithm is usually run a few times with different random initializations. One way to choose between these different solutions from different random initializations is to choose the one with the lowest cost function (distortion). You will implement the two phases of the k-means algorithm separately in the next two sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.1: Finding closest centroids (5 points)\n",
    "In the cluster assignment phase of the k-means algorithm, the algorithm\n",
    "assigns every training example $x^{(i)}$ to its closest centroid, given the current\n",
    "positions of centroids. Specifically, for every example $i$ we set\n",
    "$$ c^{(i)} = j \\; \\; \\; \\mbox{  that minimizes  } {||x^{(i)}-\\mu_j||}^2 $$\n",
    "\n",
    "where $c^{(i)}$ is the index of the centroid that is closest to $x^{(i)}$, and  $\\mu_j$ is the\n",
    "position (value) of the $j^{th}$ centroid. \n",
    "\n",
    "Your task is to complete the function **find_closest_centroids** in **utils_kmeans.py**. This\n",
    "function takes the data matrix **X** and the locations of all centroids inside\n",
    "**centroids** and outputs a one-dimensional array **idx** that holds the\n",
    "index (a value in {0, ...,K-1}, where K is total number of centroids) of the\n",
    "closest centroid to every training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ================= Part 1: Find Closest Centroids ====================\n",
    "#  To help you implement K-Means, we have divided the learning algorithm \n",
    "#  into two functions -- find_closest_centroids and compute_centroids. In this\n",
    "#  part, you shoudl complete the code in the find_closest_centroids function in \n",
    "#  util_kmeans.py\n",
    "\n",
    "#  Load an example dataset that we will be using\n",
    "\n",
    "data = scipy.io.loadmat('kmeansdata2.mat')\n",
    "X = data['X']\n",
    "\n",
    "print 'Finding closest centroids.'\n",
    "\n",
    "# Select an initial set of centroids\n",
    "K = 3; \n",
    "initial_centroids = np.array([[3,3],[6,2], [8,5]])\n",
    "\n",
    "# Find the closest centroids for the examples using the\n",
    "# initial_centroids\n",
    "\n",
    "idx = utils_kmeans.find_closest_centroids(X, initial_centroids);\n",
    "print 'Closest centroids for the first 3 examples: (should be [0 2 1]): ', idx[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.2: Computing centroid means (5 points)}\n",
    "Given assignments of every point to a centroid, the second phase of the\n",
    "algorithm recomputes, for each centroid, the mean of the points that were\n",
    "assigned to it. Specifically, for every centroid $j$ we set\n",
    "\\[ \\mu_j = \\frac{1}{|C_j|} \\sum_{i\\in C_j} x^{(i)} \\] \n",
    "where \n",
    "$C_j$ is the set of examples that are assigned to centroid $j$.\n",
    "\n",
    "You should now complete the function **compute\\_centroids** in **utils_kmeans.py**. You can\n",
    "implement this function using a loop over the centroids. You can also use a\n",
    "loop over the examples; but if you can use a vectorized implementation that\n",
    "does not use such a loop, your code should run faster.\n",
    "Once you have completed the function, the next cell \n",
    " will run your function and output the centroids after the first step of k-means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## ===================== Part 2: Compute Means =========================\n",
    "#  After implementing the closest centroids function, you should now\n",
    "#  complete the compute_centroids function in utils_kmeans.py\n",
    "#\n",
    "print 'Computing centroids means.'\n",
    "\n",
    "#  Compute means based on the closest centroids found in the previous part.\n",
    "centroids = utils_kmeans.compute_centroids(X, idx, K)\n",
    "\n",
    "print 'Centroids computed after initial finding of closest centroids:'\n",
    "print  centroids\n",
    "\n",
    "print '(the centroids should be'\n",
    "print '   [ 2.428301 3.157924 ],  [ 5.813503 2.633656 ], [ 7.119387 3.616684 ]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-means on example dataset\n",
    "\n",
    "After you have completed the two functions (find_closest_centroids and\n",
    "compute_centroids), the next cell will run the k-means algorithm\n",
    "on a toy 2D dataset to help you understand how k-means works. Your\n",
    "functions are called from inside the **run_kmeans** function in **utils_kmeans.py**. We encourage you\n",
    "to take a look at the function to understand how it works. Notice that the\n",
    "function calls the two functions you implemented in a loop.\n",
    "When you run the next step, the function will produce a visualization\n",
    "that steps you through the progress of the algorithm at each iteration.\n",
    " At the end, your figure should\n",
    "look as the one displayed in Figure 1 of your homework handout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## =================== Part 3: K-Means Clustering ======================\n",
    "#  After you have completed the two functions compute_centroids and\n",
    "#  find_closest_centroids, you have all the necessary pieces to run the\n",
    "#  kmeans algorithm. In this part, you will run the kmeans algorithm on\n",
    "#  the example dataset we have provided. \n",
    "#\n",
    "print 'Running k-means clustering on example dataset.'\n",
    "\n",
    "# Settings for running k-means\n",
    "K = 3;\n",
    "max_iters = 10;\n",
    "\n",
    "#  For consistency, here we set centroids to specific values\n",
    "#  but in practice you want to generate them automatically, such as by\n",
    "#  settings them to be random examples (as can be seen in\n",
    "#  kmeans_init_centroids).\n",
    "\n",
    "initial_centroids = np.array([[3,3],[6,2], [8,5]])\n",
    "\n",
    "# Run the k-means algorithm. The 'true' at the end tells our function to plot\n",
    "# the progress of K-Means\n",
    "[centroids, idx] = utils_kmeans.run_kmeans(X, initial_centroids, max_iters, plot_progress = True)\n",
    "print 'k-means Done.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4.3: Random initialization (5 points)\n",
    "\n",
    "The initial assignments of centroids for the example dataset  were\n",
    "designed so that you will see the same figure as in Figure 1. In practice, a\n",
    "good strategy for initializing the centroids is to select random examples from\n",
    "the training set.\n",
    "In this part of the exercise, you should complete the function **kmeans_init_centroids** in **utils_kmeans.py**.\n",
    "First, randomly permute the indices of the examples. Then, select the first K examples based on the random\n",
    "permutation of the indices. This allows the examples to be selected at random\n",
    "without the risk of selecting the same example twice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image compression with k-means\n",
    "\n",
    "In this exercise, you will apply k-means to image compression. In a\n",
    "straightforward 24-bit color representation of an image,  each pixel is represented\n",
    "as three 8-bit unsigned integers (ranging from 0 to 255) that specify\n",
    "the red, green and blue intensity values. This encoding is often refered to as\n",
    "the RGB encoding. Our image contains thousands of colors, and in this part\n",
    "of the exercise, you will reduce the number of colors to 16 colors.\n",
    "\n",
    "By making this reduction, it is possible to represent (compress) the photo\n",
    "in an efficient way. Specifically, you only need to store the RGB values of\n",
    "the 16 selected colors, and for each pixel in the image you now need to only\n",
    "store the index of the color at that location (where only 4 bits are necessary\n",
    "to represent 16 possibilities).\n",
    "In this exercise, you will use the k-means algorithm to select the 16 colors\n",
    "that will be used to represent the compressed image. In particular, you will\n",
    "treat every pixel in the original image as a data example and use the K-means\n",
    "algorithm to find the 16 colors that best group (cluster) the pixels in the 3-\n",
    "dimensional RGB space. Once you have computed the cluster centroids on\n",
    "the image, you will then use the 16 colors to replace the pixels in the original\n",
    "image.\n",
    "\n",
    "The cell below first loads the image, and then reshapes it to create\n",
    "an $m \\times 3$ matrix of pixel colors (where $m = 16384 = 128 \\times 128$), and calls\n",
    "your k-means function on it.\n",
    "After finding the top K = 16 colors to represent the image, you can now\n",
    "assign each pixel position to its closest centroid using the **find_closest_centroids**\n",
    "function. This allows you to represent the original image using the centroid\n",
    "assignments of each pixel. Notice that you have significantly reduced the\n",
    "number of bits that are required to describe the image. The original image\n",
    "required 24 bits for each one of the $128 \\times 128$  pixel locations, resulting in total\n",
    "size of $128 \\times 128 \\times 24 = 393,216$ bits. The new representation requires some\n",
    "overhead storage in form of a dictionary of 16 colors, each of which require\n",
    "24 bits, but the image itself then only requires 4 bits per pixel location. The\n",
    "final number of bits used is therefore $16 \\times 24 + 128 \\times 128 \\times 4 = 65,920$  bits,\n",
    "which corresponds to compressing the original image by about a factor of 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load an image of a bird\n",
    "\n",
    "bird = scipy.misc.imread('bird_small.png')\n",
    "\n",
    "# divide by 255 so all values are scaled 0-1\n",
    "bird = bird/255.\n",
    "\n",
    "# Reshape the image into an Nx3 matrix where N = number of pixels.\n",
    "# Each row will contain the Red, Green and Blue pixel values\n",
    "# This gives us our dataset matrix X that we will use K-Means on.\n",
    "\n",
    "r,c,_ = bird.shape\n",
    "\n",
    "X = bird.reshape((r*c,3))\n",
    "\n",
    "# now run kmeans (try other values for K to understand variation in quality of compression with K)\n",
    "K = 16\n",
    "max_iters = 10\n",
    "\n",
    "# When using K-Means, it is important the initialize the centroids\n",
    "# randomly.\n",
    "# You should complete the code in kMeansInitCentroids.m before proceeding\n",
    "initial_centroids = utils_kmeans.kmeans_init_centroids(X, K)\n",
    "\n",
    "# run kmeans\n",
    "[centroids, idx] = utils_kmeans.run_kmeans(X, initial_centroids, max_iters, plot_progress = False)\n",
    "\n",
    "# image compression\n",
    "# Find the closest centroids for each example\n",
    "idx = utils_kmeans.find_closest_centroids(X,centroids)\n",
    "\n",
    "# construct the color compressed version of X\n",
    "X_color_compressed = np.zeros(X.shape)\n",
    "X_color_compressed = centroids[idx,:]\n",
    "\n",
    "# reshape the color compressed version of X\n",
    "X_ccompressed = X_color_compressed.reshape((r,c,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# show the pictures side by side\n",
    "# Two subplots, unpack the axes array immediately\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.imshow(bird)\n",
    "ax2.imshow(X_ccompressed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
