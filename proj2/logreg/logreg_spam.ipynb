{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regularized logistic regression to classify email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Penalty experiments -----------\n",
      "best_lambda =  0.1\n",
      "Coefficients =  [-4.86311364] [[ -2.74146434e-02  -2.25297594e-01   1.21840935e-01   2.29362877e+00\n",
      "    2.70425715e-01   2.32851164e-01   9.28595395e-01   2.95200237e-01\n",
      "    1.62205936e-01   6.78260398e-02  -8.32604402e-02  -1.60373355e-01\n",
      "   -4.72247673e-02   1.07677115e-02   1.87903349e-01   8.19771812e-01\n",
      "    5.09528972e-01   3.98711522e-02   2.67729696e-01   3.47047572e-01\n",
      "    2.60498922e-01   3.64605201e-01   7.25019570e-01   1.96728250e-01\n",
      "   -3.15395701e+00  -4.03133787e-01  -1.25451044e+01  -6.16581087e-02\n",
      "   -1.56114610e+00  -5.51429773e-02  -3.00815658e-02   4.07263535e-01\n",
      "   -3.68156444e-01  -1.43611784e+00  -5.87180562e-01   4.44294899e-01\n",
      "    4.23159453e-02  -1.56897094e-01  -4.55330842e-01  -1.02250291e-01\n",
      "   -3.54273294e+00  -1.72944488e+00  -4.37529294e-01  -1.05999941e+00\n",
      "   -9.18599330e-01  -1.75490329e+00  -1.67475857e-01  -9.56875252e-01\n",
      "   -3.65653140e-01  -1.36535508e-01  -6.58692484e-02   2.06714029e-01\n",
      "    1.70694384e+00   1.21460314e+00  -3.35269867e-01   1.56141406e+00\n",
      "    3.68775706e-01]]\n",
      "Accuracy on set aside test set for  std  =  0.9296875\n",
      "best_lambda =  0.6\n",
      "Coefficients =  [-4.60945017] [[-0.45145974 -0.2846657  -0.06328476  0.68295739  1.2105317   0.91504849\n",
      "   2.83046004  1.43676917  0.24145365  0.35775043 -0.38641254 -0.48142355\n",
      "  -0.69586735  0.37457213  0.64885415  1.53956261  1.38118714  0.0719795\n",
      "   0.37641709  0.63501673  0.52275319  0.38563575  2.00137914  1.50817836\n",
      "  -3.1406056  -0.66618018 -4.90648278 -0.03261142 -1.28886232 -0.15745872\n",
      "  -0.63898794 -0.30227971 -1.00990483 -0.42568141 -1.0872114   1.28430674\n",
      "  -0.90559315 -0.35285735 -1.12971262 -0.62587379 -1.4033674  -2.44122669\n",
      "  -1.55652635 -1.94778347 -1.13112579 -2.7999069  -0.75122366 -2.11600915\n",
      "  -1.68510082 -0.66772936 -0.6912527   2.06913851  4.21978003  0.76309282\n",
      "   0.70345811  0.17008794  0.43018773]]\n",
      "Accuracy on set aside test set for  logt  =  0.943359375\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-1.82566816] [[ -1.78313887e-01  -1.60085506e-01  -3.73001110e-01   2.36358803e-01\n",
      "    9.46367588e-01   1.59613651e-01   2.03690641e+00   7.62617294e-01\n",
      "    1.81159712e-01   3.12388353e-01  -2.60352275e-01  -4.14115142e-01\n",
      "   -8.66097179e-01   2.36335390e-01   4.75358415e-01   1.43030139e+00\n",
      "    8.23118667e-01  -6.18540142e-02   2.39595773e-01   4.50237962e-01\n",
      "    7.24354332e-01   1.06352180e+00   8.70212070e-01   1.30340906e+00\n",
      "   -2.20348245e+00  -4.57176451e-01  -3.39242058e+00   5.45347540e-01\n",
      "   -5.60588209e-01  -1.85244388e-01  -8.05548612e-01  -4.84223733e-01\n",
      "   -6.36751901e-01  -8.68074832e-02  -6.31860077e-01   3.04485691e-01\n",
      "   -1.03756760e+00   4.18380738e-01  -7.08628405e-01  -2.18361509e-01\n",
      "   -1.07385026e+00  -1.74862153e+00  -6.95533233e-01  -1.43004581e+00\n",
      "   -7.40200632e-01  -2.11078935e+00  -9.46977030e-02  -1.24285032e+00\n",
      "   -2.91376072e-01   1.90460650e-01  -1.65731167e-01   1.19345678e+00\n",
      "    1.42337675e+00   6.04361397e-02   7.86190087e-04   7.86190087e-04\n",
      "    7.86190087e-04]]\n",
      "Accuracy on set aside test set for  bin  =  0.928385416667\n",
      "L1 Penalty experiments -----------\n",
      "best_lambda =  4.6\n",
      "Coefficients =  [-1.58190218] [[-0.01060917 -0.15862728  0.12271282  0.20867808  0.24908482  0.17674445\n",
      "   0.91085777  0.28987808  0.13941496  0.04856908 -0.02288972 -0.13974172\n",
      "  -0.00714876  0.00922381  0.15409876  0.75696583  0.46013269  0.07052554\n",
      "   0.25403526  0.19592621  0.24318346  0.34681291  0.72736608  0.23437898\n",
      "  -2.33558191 -0.35770178 -3.13464863 -0.0108644  -0.37011878  0.          0.\n",
      "   0.         -0.32778715  0.         -0.06112626  0.24286703  0.\n",
      "  -0.11596429 -0.31120165 -0.044117   -0.23776782 -0.7951463  -0.19066963\n",
      "  -0.5633665  -0.73359307 -1.17914861 -0.08547372 -0.5130689  -0.25651989\n",
      "  -0.13391788 -0.05682983  0.2185145   1.64839452  0.22180289  0.\n",
      "   0.64706302  0.33299691]]\n",
      "Accuracy on set aside test set for  std  =  0.921875\n",
      "best_lambda =  1.6\n",
      "Coefficients =  [-4.46352714] [[-0.34345379 -0.09557987  0.          0.12933314  1.18462859  0.69054709\n",
      "   2.91334304  1.37686817  0.          0.29512668  0.         -0.48054537\n",
      "  -0.32787123  0.10733468  0.          1.49528634  1.34900434  0.\n",
      "   0.35497139  0.19676001  0.49440698  0.34744935  1.78468487  1.32953803\n",
      "  -3.49777155 -0.26964407 -7.49454885  0.         -0.41750067  0.          0.\n",
      "   0.         -0.79143586  0.         -0.23864936  0.87193938 -0.77442639\n",
      "   0.         -0.88296461  0.         -0.30403942 -2.35516892 -0.69465025\n",
      "  -1.66133675 -1.13792783 -2.98252218  0.         -1.90112102 -1.24511801\n",
      "  -0.30350237  0.          2.01464892  5.36650063  0.          0.63710643\n",
      "   0.2016796   0.38822961]]\n",
      "Accuracy on set aside test set for  logt  =  0.944010416667\n",
      "best_lambda =  3.6\n",
      "Coefficients =  [-0.36299938] [[ 0.          0.         -0.19323493  0.          0.86542967  0.\n",
      "   2.02913464  0.63314982  0.0265389   0.21330929  0.         -0.42077094\n",
      "  -0.68105456  0.          0.          1.31575487  0.76585463  0.\n",
      "   0.10373841  0.12321429  0.63675939  0.73018688  0.62198602  1.18401348\n",
      "  -2.42395714 -0.12608003 -3.73129701  0.          0.          0.          0.\n",
      "   0.         -0.28803258  0.         -0.21898527  0.         -1.01548724\n",
      "   0.         -0.40497268  0.         -0.11545865 -1.69440883 -0.03927439\n",
      "  -1.10986414 -0.68727303 -2.21942153  0.         -1.02542256 -0.12516941\n",
      "   0.07419254  0.          1.15116019  1.49904103  0.         -0.32308158\n",
      "  -0.47664648 -0.50256663]]\n",
      "Accuracy on set aside test set for  bin  =  0.92578125\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import utils\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "\n",
    "# No modifications in this script\n",
    "# complete the functions in util.py; then run the script\n",
    "\n",
    "# load the spam data in\n",
    "\n",
    "Xtrain,Xtest,ytrain,ytest = utils.load_spam_data()\n",
    "\n",
    "# Preprocess the data \n",
    "\n",
    "Xtrain_std,mu,sigma = utils.std_features(Xtrain)\n",
    "Xtrain_logt = utils.log_features(Xtrain)\n",
    "Xtrain_bin = utils.bin_features(Xtrain)\n",
    "\n",
    "Xtest_std = (Xtest - mu)/sigma\n",
    "Xtest_logt = utils.log_features(Xtest)\n",
    "Xtest_bin = utils.bin_features(Xtest)\n",
    "\n",
    "# find good lambda by cross validation for these three sets\n",
    "\n",
    "def run_dataset(X,ytrain,Xt,ytest,type,penalty):\n",
    "\n",
    "    best_lambda = utils.select_lambda_crossval(X,ytrain,0.1,5.1,0.5,penalty)\n",
    "    print \"best_lambda = \", best_lambda\n",
    "\n",
    "    # train a classifier on best_lambda and run it\n",
    "    if penalty == \"l2\":\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='lbfgs',fit_intercept=True)\n",
    "    else:\n",
    "        lreg = linear_model.LogisticRegression(penalty=penalty,C=1.0/best_lambda, solver='liblinear',fit_intercept=True)\n",
    "    lreg.fit(X,ytrain)\n",
    "    print \"Coefficients = \", lreg.intercept_,lreg.coef_\n",
    "    predy = lreg.predict(Xt)\n",
    "    print \"Accuracy on set aside test set for \", type, \" = \", np.mean(predy==ytest)\n",
    "\n",
    "print \"L2 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l2\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l2\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l2\")\n",
    "\n",
    "print \"L1 Penalty experiments -----------\"\n",
    "run_dataset(Xtrain_std,ytrain,Xtest_std,ytest,\"std\",\"l1\")\n",
    "run_dataset(Xtrain_logt,ytrain,Xtest_logt,ytest,\"logt\",\"l1\")\n",
    "run_dataset(Xtrain_bin,ytrain,Xtest_bin,ytest,\"bin\",\"l1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
